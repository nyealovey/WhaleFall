# 查询下推与统计聚合重构方案（修复 .all() 拉全量导致 OOM/超时）

- 生成日期：2025-12-22
- 背景：见 `docs/refactoring/new/数据库模型与迁移评审报告.md` 的 P0/4「多条关键路径使用 .all() 拉全量再 Python 计算」。
- 目标：把“全量拉取 + Python 计数/去重/求和”改为“SQL 聚合/窗口函数下推”，避免数据量到百万/千万级后 API 超时、worker OOM。

---

## 0. 范围与现状定位（4 条 Top 路径）

1) 分区页核心指标窗口（四张表 .all()）
- 位置：`app/routes/partition.py:185-207`
- 现状：按日期窗口把 `database_size_stats / instance_size_stats / database_size_aggregations / instance_size_aggregations` 全量拉回，再在 Python 逐行计数。
- 实际需求：仅需“按日/按周期”的数量曲线（count），不需要明细行。

2) 实例详情-容量“最新记录”（全量拉取再去重）
- 位置：`app/routes/instances/detail.py:590-688`
- 现状：按 `database_name asc, collected_date desc` 拉回全部历史行，再用 Python `lower()` 去重拿每库最新一条。
- 实际需求：每个数据库仅需 1 条最新记录（+可选占位的 inactive 数据库）；并支持分页与汇总。

3) 仪表盘-账户汇总（.all() 后 Python 统计）
- 位置：`app/services/statistics/account_statistics_service.py:83-139`
- 现状：拉回所有账户权限快照行，再按 `instance_account.is_active` 与锁定逻辑在 Python 计数。
- 实际需求：仅需计数（total/active/locked/normal/deleted），不需要逐行对象。

4) 仪表盘-容量汇总（最近 N 天 .all() 后取每实例最新）
- 位置：`app/services/statistics/instance_statistics_service.py:70-117`
- 现状：拉回最近 N 天所有实例容量行，再在 Python 取每实例最新一条并求和。
- 实际需求：仅需“每实例最新一条”的总和（sum），不需要逐行对象。

---

## 1. 统一原则（本次重构的“查询下推规范”）

### 1.1 禁止模式（高风险）
- 大表查询后 `.all()` → Python `for` 循环做 `count/sum/max/dedup`。
- 先 `order_by(...).all()` 再 Python `set()` 去重取“最新/第一条”。

### 1.2 推荐模式（安全/可扩展）
- “计数/求和/分组”统一下推：`COUNT/SUM/GROUP BY`。
- “每组最新一条”统一下推：`row_number() over(partition by ... order by ... desc)` 或 Postgres `DISTINCT ON`。
- 大表分页优先 keyset（中期任务）；本次只保证移除全量 `.all()`。

---

## 2. 分项改造方案（短期可落地）

### 2.1 分区页核心指标窗口：改为按日/按周期聚合计数

#### 改造点
- 将 `_load_core_metric_records()` 改为“聚合计数查询”，直接返回 4 组 `date -> count` 映射：
  - `database_size_stats`：按 `collected_date` 分组计数
  - `instance_size_stats`：按 `collected_date` 分组计数
  - `database_size_aggregations`：按 `period_start` 分组计数（带 `period_type` 条件）
  - `instance_size_aggregations`：按 `period_start` 分组计数（带 `period_type` 条件）

#### SQLAlchemy 伪代码
```python
db_stats_counts = dict(
    db.session.query(DatabaseSizeStat.collected_date, func.count())
    .filter(DatabaseSizeStat.collected_date.between(window.stats_start, window.stats_end))
    .group_by(DatabaseSizeStat.collected_date)
    .all()
)
```

#### 兼容性/语义保持
- 现有图表语义是“记录数曲线”（不是 distinct 实例/数据库数），按日 `count(*)` 等价于 Python 逐行 `+=1`。
- `_rollup_period_metrics()` 的周/月/季“均值”逻辑继续沿用：它只依赖每日 count 值，不依赖明细行。

#### 额外建议（可选）
- 为 `GET /partition/api/aggregations/core-metrics` 增加短缓存（如 60s），避免重复查询相同窗口。

---

### 2.2 实例详情容量最新记录：改为“每库最新一条”窗口函数/Distinct On

#### 目标语义
- 对同一实例、同一数据库（大小写不敏感）只返回最新一条记录。
- `include_inactive=false` 时：过滤掉 `instance_databases.is_active=false` 的库（但当 join 为空时视为 active，保持现状）。
- 仍保留“inactive 占位项”逻辑（当 include_inactive=true 或没有任何 stats 时）。

#### 方案 A（短期推荐）：窗口函数下推，无需改表
- 用 `row_number()` 按 `lower(database_name)` 分组，按 `collected_date desc, collected_at desc` 排序取 rn=1。
- 先拿“每库最新”集合，再做分页/汇总；避免全量历史拉取。

#### SQLAlchemy 伪代码
```python
key = func.lower(DatabaseSizeStat.database_name)
ranked = (
    db.session.query(
        DatabaseSizeStat,
        InstanceDatabase.is_active,
        InstanceDatabase.deleted_at,
        InstanceDatabase.last_seen_date,
        func.row_number().over(
            partition_by=key,
            order_by=(DatabaseSizeStat.collected_date.desc(), DatabaseSizeStat.collected_at.desc()),
        ).label("rn"),
    )
    .outerjoin(InstanceDatabase, ...)
    .filter(DatabaseSizeStat.instance_id == instance_id, ...)
).subquery()

latest = db.session.query(ranked).filter(ranked.c.rn == 1)
```

#### 方案 B（你提出的“tag/最新标记”思路，建议改成更明确的数据结构）
你提的思路本质是“把 latest 这个计算结果固化”，可显著降低查询成本，但不建议复用业务标签 `tags` 表做 latest（语义混乱、约束难做）。

更推荐两种落库方式（中期）：
- **B1：小表 `database_size_latest`（推荐）**
  - 结构：`(instance_id, database_name_canonical, stat_id, collected_at, size_mb, ...)`
  - 约束：`UNIQUE(instance_id, database_name_canonical)`；可加索引支持检索/排序。
  - 写入：容量同步时 upsert 维护该表；历史表仍保留用于趋势与审计。
  - 优点：避免在大分区表上做“更新旧 latest 行”这种写放大；读取 O(库数)。
- **B2：在 `instance_databases` 增加 latest 字段**
  - 新增列：`latest_size_mb / latest_collected_at / latest_stat_id`。
  - 写入：同步容量时按库更新对应 `instance_databases` 记录。
  - 优点：无需新表，天然与 active/inactive 结合；缺点是需要保证同步顺序与一致性。

> 若坚持“在大表上加 tag/flag”，建议用明确列名 `is_latest`，并配合部分唯一索引保证每库仅 1 条 latest；但该方案会引入跨分区更新写放大，不作为首选。

---

### 2.3 仪表盘账户汇总：改为条件聚合（COUNT + CASE）

#### 改造点
- 用一条聚合 SQL 返回：
  - `total_accounts = COUNT(*)`
  - `active_accounts = SUM(CASE WHEN instance_accounts.is_active THEN 1 ELSE 0 END)`
  - `locked_accounts = SUM(CASE WHEN instance_accounts.is_active AND account_permission.is_locked THEN 1 ELSE 0 END)`
  - 其余字段由这三项推导（保持现状：normal=active-locked；deleted=total-active）

#### 兼容性/语义保持
- 现状锁定判断 `_is_account_locked()` 的第一优先级是 `account.is_locked`，且目前 schema 已是 `NOT NULL`，因此直接用列计算可保持一致。
- 若需要兼容历史库（存在 `is_locked` 为 NULL 的旧数据），再把旧 `type_specific` fallback 映射写入 SQL CASE（建议仅保留过渡期）。

#### 额外建议（关联但不阻塞）
- 评审报告 P1/6 已指出 SQLServer 的 `type_specific` 键名漂移（is_disabled vs is_locked）；建议把“锁定语义”彻底收敛为 `account_permission.is_locked`，并做一次性回填后删掉 fallback 路径。

---

### 2.4 仪表盘容量汇总：改为“每实例最新一条”下推后再 SUM

#### 方案（短期推荐）：窗口函数 + SUM
- 在 `instance_size_stats` 上按 `instance_id` 分组取 `collected_date desc` 的 rn=1，再 sum `total_size_mb`。
- 限定 `collected_date >= recent_date` + `instances` 活跃条件，确保分区剪枝/索引命中。

#### SQLAlchemy 伪代码
```python
ranked = (
    db.session.query(
        InstanceSizeStat.instance_id.label("instance_id"),
        InstanceSizeStat.total_size_mb.label("total_size_mb"),
        func.row_number().over(
            partition_by=InstanceSizeStat.instance_id,
            order_by=InstanceSizeStat.collected_date.desc(),
        ).label("rn"),
    )
    .join(Instance, Instance.id == InstanceSizeStat.instance_id)
    .filter(
        InstanceSizeStat.collected_date >= recent_date,
        Instance.is_active.is_(True),
        Instance.deleted_at.is_(None),
        # 若存在软删除：InstanceSizeStat.is_deleted.is_(False),
    )
).subquery()

total_mb = db.session.query(func.coalesce(func.sum(ranked.c.total_size_mb), 0)).filter(ranked.c.rn == 1).scalar()
```

---

## 3. 索引与数据结构建议（按“短期不强制 / 中期建议”）

### 3.1 短期（不改表即可见效）
- 分区页：现有索引已覆盖 `collected_date` 与 `(period_type, period_start)`，无需额外索引即可消除 OOM。
- 容量最新记录：优先靠分区剪枝（`collected_date` 范围）与现有 `uq_daily_database_size`/`ix_instance_date`；必要时再补函数索引。

### 3.2 中期（建议纳入迁移）
- `database_size_stats`：
  - 若持续需要“按库最新”且存在大小写去重：考虑加 `lower(database_name)` 的函数索引，或引入 canonical 列并以其做索引。
- `instance_size_stats`：
  - 建议补 `(instance_id, collected_date desc)`（或部分索引 `WHERE is_deleted=false`）以优化“取最新”窗口函数。
- 若采用“latest 小表/列”：为 latest 表/列提供 `UNIQUE(instance_id, name_canonical)` + 支持分页/搜索的索引。

---

## 4. 验证与基线（必须）

### 4.1 每条 Top 查询补 EXPLAIN 基线
- 输出：`EXPLAIN (ANALYZE, BUFFERS)`，记录 planning/exec time、rows/loops、是否触发分区剪枝。
- 要求：随数据量增长近似线性；或被分区/索引明显压住。

### 4.2 staging 造数演练
- `database_size_stats`：至少千万行量级（按实例数×数据库数×天数构造），覆盖大小写混杂与 inactive 数据库场景。
- 重点回归：分区页 core-metrics、仪表盘 overview、实例详情容量 latest_only。

---

## 5. 发布与回滚策略

### 5.1 发布顺序（建议）
1) 先合并查询下推（不改表），确保功能等价并补 EXPLAIN 基线。
2) 若 EXPLAIN 仍不理想，再补索引（优先 CONCURRENTLY/在线方式）。
3) 中期再做 latest 小表/列，最后删掉旧的 Python 去重与历史 fallback。

### 5.2 回滚
- 代码层：保留旧逻辑为临时开关（如 config/feature flag）仅用于紧急回退；验证稳定后移除。
- 数据层：索引新增可保留；latest 小表可独立回滚（不影响历史表）。

