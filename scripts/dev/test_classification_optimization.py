#!/usr/bin/env python3
"""
é²¸è½ - è‡ªåŠ¨åˆ†ç±»ä¼˜åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•é˜¶æ®µ1ä¼˜åŒ–ï¼ˆæ–¹æ¡ˆBï¼‰çš„æ•ˆæœ
"""

import os
import sys
import time
import json
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from app import create_app
from app.services.optimized_account_classification_service import OptimizedAccountClassificationService
from app.services.cache_manager import cache_manager
from app.models.current_account_sync_data import CurrentAccountSyncData
from app.models.account_classification import ClassificationRule
from app.models.instance import Instance
from app.utils.structlog_config import log_info, log_error


class ClassificationOptimizationTester:
    """è‡ªåŠ¨åˆ†ç±»ä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.app = create_app()
        self.service = OptimizedAccountClassificationService()
        self.results = {}
    
    def run_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è‡ªåŠ¨åˆ†ç±»ä¼˜åŒ–æµ‹è¯•...")
        
        with self.app.app_context():
            try:
                # 1. æµ‹è¯•é¢„åˆ†ç»„ä¼˜åŒ–
                self.test_pre_grouping_optimization()
                
                # 2. æµ‹è¯•è§„åˆ™è¿‡æ»¤ä¼˜åŒ–
                self.test_rule_filtering_optimization()
                
                # 3. æµ‹è¯•ç¼“å­˜ä¼˜åŒ–
                self.test_cache_optimization()
                
                # 4. æµ‹è¯•æ•´ä½“æ€§èƒ½
                self.test_overall_performance()
                
                # 5. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
                self.generate_test_report()
                
            except Exception as e:
                log_error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}", module="classification_test")
                print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
    
    def test_pre_grouping_optimization(self):
        """æµ‹è¯•é¢„åˆ†ç»„ä¼˜åŒ–"""
        print("\nğŸ“Š æµ‹è¯•é¢„åˆ†ç»„ä¼˜åŒ–...")
        
        try:
            # è·å–æµ‹è¯•æ•°æ®
            accounts = CurrentAccountSyncData.query.join(Instance).limit(100).all()
            rules = ClassificationRule.query.filter_by(is_active=True).limit(20).all()
            
            if not accounts or not rules:
                print("âš ï¸  æµ‹è¯•æ•°æ®ä¸è¶³ï¼Œè·³è¿‡é¢„åˆ†ç»„æµ‹è¯•")
                return
            
            # æµ‹è¯•é¢„åˆ†ç»„åŠŸèƒ½
            start_time = time.time()
            accounts_by_db_type = self.service._group_accounts_by_db_type(accounts)
            rules_by_db_type = self.service._group_rules_by_db_type(rules)
            grouping_time = time.time() - start_time
            
            # ç»Ÿè®¡ç»“æœ
            db_types = list(accounts_by_db_type.keys())
            total_accounts = sum(len(accs) for accs in accounts_by_db_type.values())
            total_rules = sum(len(rules) for rules in rules_by_db_type.values())
            
            self.results["pre_grouping"] = {
                "success": True,
                "grouping_time": grouping_time,
                "db_types": db_types,
                "total_accounts": total_accounts,
                "total_rules": total_rules,
                "accounts_per_type": {db_type: len(accs) for db_type, accs in accounts_by_db_type.items()},
                "rules_per_type": {db_type: len(rules) for db_type, rules in rules_by_db_type.items()}
            }
            
            print(f"âœ… é¢„åˆ†ç»„ä¼˜åŒ–æµ‹è¯•å®Œæˆ")
            print(f"   - åˆ†ç»„æ—¶é—´: {grouping_time:.3f}s")
            print(f"   - æ•°æ®åº“ç±»å‹: {', '.join(db_types)}")
            print(f"   - è´¦æˆ·æ€»æ•°: {total_accounts}")
            print(f"   - è§„åˆ™æ€»æ•°: {total_rules}")
            
        except Exception as e:
            log_error(f"é¢„åˆ†ç»„ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}", module="classification_test")
            self.results["pre_grouping"] = {"success": False, "error": str(e)}
            print(f"âŒ é¢„åˆ†ç»„ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
    
    def test_rule_filtering_optimization(self):
        """æµ‹è¯•è§„åˆ™è¿‡æ»¤ä¼˜åŒ–"""
        print("\nğŸ” æµ‹è¯•è§„åˆ™è¿‡æ»¤ä¼˜åŒ–...")
        
        try:
            # è·å–æµ‹è¯•æ•°æ®
            accounts = CurrentAccountSyncData.query.join(Instance).limit(50).all()
            rules = ClassificationRule.query.filter_by(is_active=True).limit(10).all()
            
            if not accounts or not rules:
                print("âš ï¸  æµ‹è¯•æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è§„åˆ™è¿‡æ»¤æµ‹è¯•")
                return
            
            # æµ‹è¯•è§„åˆ™è¿‡æ»¤åŠŸèƒ½
            start_time = time.time()
            
            # æ¨¡æ‹ŸæŒ‰æ•°æ®åº“ç±»å‹è¿‡æ»¤
            accounts_by_db_type = self.service._group_accounts_by_db_type(accounts)
            rules_by_db_type = self.service._group_rules_by_db_type(rules)
            
            filtered_operations = 0
            total_operations = 0
            
            for db_type, db_accounts in accounts_by_db_type.items():
                db_rules = rules_by_db_type.get(db_type, [])
                for rule in db_rules:
                    # æµ‹è¯•ä¼˜åŒ–çš„è§„åˆ™åŒ¹é…
                    matched_accounts = self.service._find_accounts_matching_rule_optimized(
                        rule, db_accounts, db_type
                    )
                    filtered_operations += 1
                    total_operations += len(db_accounts)
            
            filtering_time = time.time() - start_time
            
            # è®¡ç®—ä¼˜åŒ–æ•ˆæœ
            original_operations = len(accounts) * len(rules)
            optimization_ratio = (original_operations - total_operations) / original_operations if original_operations > 0 else 0
            
            self.results["rule_filtering"] = {
                "success": True,
                "filtering_time": filtering_time,
                "original_operations": original_operations,
                "optimized_operations": total_operations,
                "filtered_operations": filtered_operations,
                "optimization_ratio": optimization_ratio,
                "time_saved": original_operations - total_operations
            }
            
            print(f"âœ… è§„åˆ™è¿‡æ»¤ä¼˜åŒ–æµ‹è¯•å®Œæˆ")
            print(f"   - è¿‡æ»¤æ—¶é—´: {filtering_time:.3f}s")
            print(f"   - åŸå§‹æ“ä½œæ•°: {original_operations}")
            print(f"   - ä¼˜åŒ–åæ“ä½œæ•°: {total_operations}")
            print(f"   - ä¼˜åŒ–æ¯”ä¾‹: {optimization_ratio:.2%}")
            print(f"   - èŠ‚çœæ“ä½œæ•°: {original_operations - total_operations}")
            
        except Exception as e:
            log_error(f"è§„åˆ™è¿‡æ»¤ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}", module="classification_test")
            self.results["rule_filtering"] = {"success": False, "error": str(e)}
            print(f"âŒ è§„åˆ™è¿‡æ»¤ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
    
    def test_cache_optimization(self):
        """æµ‹è¯•ç¼“å­˜ä¼˜åŒ–"""
        print("\nğŸ’¾ æµ‹è¯•ç¼“å­˜ä¼˜åŒ–...")
        
        try:
            if not cache_manager:
                print("âš ï¸  ç¼“å­˜ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡ç¼“å­˜æµ‹è¯•")
                return
            
            # æµ‹è¯•æŒ‰æ•°æ®åº“ç±»å‹çš„ç¼“å­˜
            db_types = ["mysql", "postgresql", "sqlserver", "oracle"]
            cache_stats = {}
            
            for db_type in db_types:
                # æµ‹è¯•è§„åˆ™ç¼“å­˜
                rules_cache = cache_manager.get_classification_rules_by_db_type_cache(db_type)
                # æµ‹è¯•è´¦æˆ·ç¼“å­˜
                accounts_cache = cache_manager.get_accounts_by_db_type_cache(db_type)
                
                cache_stats[db_type] = {
                    "rules_cached": rules_cache is not None,
                    "rules_count": len(rules_cache) if rules_cache else 0,
                    "accounts_cached": accounts_cache is not None,
                    "accounts_count": len(accounts_cache) if accounts_cache else 0
                }
            
            # æµ‹è¯•ç¼“å­˜æ€§èƒ½
            start_time = time.time()
            
            # æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ
            test_data = [{"id": i, "name": f"test_{i}"} for i in range(10)]
            
            for db_type in db_types:
                cache_manager.set_classification_rules_by_db_type_cache(db_type, test_data)
                cached_data = cache_manager.get_classification_rules_by_db_type_cache(db_type)
                cache_manager.invalidate_db_type_cache(db_type)
            
            cache_time = time.time() - start_time
            
            self.results["cache_optimization"] = {
                "success": True,
                "cache_time": cache_time,
                "cache_stats": cache_stats,
                "db_types_tested": len(db_types)
            }
            
            print(f"âœ… ç¼“å­˜ä¼˜åŒ–æµ‹è¯•å®Œæˆ")
            print(f"   - ç¼“å­˜æ“ä½œæ—¶é—´: {cache_time:.3f}s")
            print(f"   - æµ‹è¯•æ•°æ®åº“ç±»å‹: {len(db_types)}")
            
            for db_type, stats in cache_stats.items():
                print(f"   - {db_type}: è§„åˆ™ç¼“å­˜={stats['rules_cached']}, è´¦æˆ·ç¼“å­˜={stats['accounts_cached']}")
            
        except Exception as e:
            log_error(f"ç¼“å­˜ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}", module="classification_test")
            self.results["cache_optimization"] = {"success": False, "error": str(e)}
            print(f"âŒ ç¼“å­˜ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
    
    def test_overall_performance(self):
        """æµ‹è¯•æ•´ä½“æ€§èƒ½"""
        print("\nâš¡ æµ‹è¯•æ•´ä½“æ€§èƒ½...")
        
        try:
            # è·å–æµ‹è¯•æ•°æ®
            accounts = CurrentAccountSyncData.query.join(Instance).limit(20).all()
            
            if not accounts:
                print("âš ï¸  æµ‹è¯•æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æ•´ä½“æ€§èƒ½æµ‹è¯•")
                return
            
            # æµ‹è¯•ä¼˜åŒ–åçš„åˆ†ç±»æ€§èƒ½
            start_time = time.time()
            
            result = self.service.auto_classify_accounts_optimized(
                instance_id=None,
                batch_type="test",
                created_by=1
            )
            
            classification_time = time.time() - start_time
            
            self.results["overall_performance"] = {
                "success": result.get("success", False),
                "classification_time": classification_time,
                "total_accounts": result.get("total_accounts", 0),
                "total_rules": result.get("total_rules", 0),
                "classified_accounts": result.get("classified_accounts", 0),
                "total_classifications_added": result.get("total_classifications_added", 0),
                "total_matches": result.get("total_matches", 0),
                "failed_count": result.get("failed_count", 0),
                "db_type_results": result.get("db_type_results", {})
            }
            
            print(f"âœ… æ•´ä½“æ€§èƒ½æµ‹è¯•å®Œæˆ")
            print(f"   - åˆ†ç±»æ—¶é—´: {classification_time:.3f}s")
            print(f"   - å¤„ç†è´¦æˆ·: {result.get('total_accounts', 0)}")
            print(f"   - åº”ç”¨è§„åˆ™: {result.get('total_rules', 0)}")
            print(f"   - åˆ†ç±»è´¦æˆ·: {result.get('classified_accounts', 0)}")
            print(f"   - æ·»åŠ åˆ†ç±»: {result.get('total_classifications_added', 0)}")
            print(f"   - åŒ¹é…æ¬¡æ•°: {result.get('total_matches', 0)}")
            print(f"   - å¤±è´¥æ¬¡æ•°: {result.get('failed_count', 0)}")
            
        except Exception as e:
            log_error(f"æ•´ä½“æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}", module="classification_test")
            self.results["overall_performance"] = {"success": False, "error": str(e)}
            print(f"âŒ æ•´ä½“æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        try:
            report = {
                "test_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "optimization_version": "é˜¶æ®µ1ä¼˜åŒ–ï¼ˆæ–¹æ¡ˆBï¼‰",
                "test_results": self.results,
                "summary": self._generate_summary()
            }
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            report_file = os.path.join(project_root, "userdata", "logs", "classification_optimization_test_report.json")
            os.makedirs(os.path.dirname(report_file), exist_ok=True)
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
            print(f"   - é¢„åˆ†ç»„ä¼˜åŒ–: {'âœ… é€šè¿‡' if self.results.get('pre_grouping', {}).get('success') else 'âŒ å¤±è´¥'}")
            print(f"   - è§„åˆ™è¿‡æ»¤ä¼˜åŒ–: {'âœ… é€šè¿‡' if self.results.get('rule_filtering', {}).get('success') else 'âŒ å¤±è´¥'}")
            print(f"   - ç¼“å­˜ä¼˜åŒ–: {'âœ… é€šè¿‡' if self.results.get('cache_optimization', {}).get('success') else 'âŒ å¤±è´¥'}")
            print(f"   - æ•´ä½“æ€§èƒ½: {'âœ… é€šè¿‡' if self.results.get('overall_performance', {}).get('success') else 'âŒ å¤±è´¥'}")
            
        except Exception as e:
            log_error(f"ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}", module="classification_test")
            print(f"âŒ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ€»ç»“"""
        summary = {
            "total_tests": len(self.results),
            "passed_tests": 0,
            "failed_tests": 0,
            "performance_metrics": {}
        }
        
        for test_name, result in self.results.items():
            if result.get("success"):
                summary["passed_tests"] += 1
            else:
                summary["failed_tests"] += 1
            
            # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
            if "time" in result:
                summary["performance_metrics"][f"{test_name}_time"] = result["time"]
        
        return summary


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‹ é²¸è½ - è‡ªåŠ¨åˆ†ç±»ä¼˜åŒ–æµ‹è¯•")
    print("=" * 50)
    
    tester = ClassificationOptimizationTester()
    tester.run_tests()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
